{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e7544011934e9081562780a12d8986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26421880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3098480848c14199ad940f6bef29157f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29515.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677fd0808ed34fc7b06ba1ffba42a50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4422102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0a9ad779b344d994f75ce31e64004f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x237d4798f88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X[18].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307933  [    0/60000]\n",
      "loss: 2.290039  [ 6400/60000]\n",
      "loss: 2.269517  [12800/60000]\n",
      "loss: 2.263105  [19200/60000]\n",
      "loss: 2.251531  [25600/60000]\n",
      "loss: 2.216510  [32000/60000]\n",
      "loss: 2.238684  [38400/60000]\n",
      "loss: 2.196434  [44800/60000]\n",
      "loss: 2.198551  [51200/60000]\n",
      "loss: 2.170820  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 36.2%, Avg loss: 2.158302 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.171908  [    0/60000]\n",
      "loss: 2.158815  [ 6400/60000]\n",
      "loss: 2.100465  [12800/60000]\n",
      "loss: 2.121365  [19200/60000]\n",
      "loss: 2.072857  [25600/60000]\n",
      "loss: 2.006757  [32000/60000]\n",
      "loss: 2.052173  [38400/60000]\n",
      "loss: 1.966307  [44800/60000]\n",
      "loss: 1.979067  [51200/60000]\n",
      "loss: 1.911875  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.901579 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.936042  [    0/60000]\n",
      "loss: 1.903388  [ 6400/60000]\n",
      "loss: 1.785314  [12800/60000]\n",
      "loss: 1.828377  [19200/60000]\n",
      "loss: 1.717983  [25600/60000]\n",
      "loss: 1.664704  [32000/60000]\n",
      "loss: 1.697000  [38400/60000]\n",
      "loss: 1.591964  [44800/60000]\n",
      "loss: 1.616929  [51200/60000]\n",
      "loss: 1.515992  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.526812 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.596220  [    0/60000]\n",
      "loss: 1.558033  [ 6400/60000]\n",
      "loss: 1.406083  [12800/60000]\n",
      "loss: 1.472449  [19200/60000]\n",
      "loss: 1.351258  [25600/60000]\n",
      "loss: 1.346994  [32000/60000]\n",
      "loss: 1.359759  [38400/60000]\n",
      "loss: 1.286642  [44800/60000]\n",
      "loss: 1.319744  [51200/60000]\n",
      "loss: 1.223581  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 1.248034 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.328592  [    0/60000]\n",
      "loss: 1.310591  [ 6400/60000]\n",
      "loss: 1.142874  [12800/60000]\n",
      "loss: 1.240798  [19200/60000]\n",
      "loss: 1.116855  [25600/60000]\n",
      "loss: 1.141203  [32000/60000]\n",
      "loss: 1.156698  [38400/60000]\n",
      "loss: 1.103160  [44800/60000]\n",
      "loss: 1.138019  [51200/60000]\n",
      "loss: 1.060598  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.080229 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
